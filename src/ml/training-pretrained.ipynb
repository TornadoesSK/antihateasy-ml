{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from pytorch_lightning import Trainer, LightningModule, LightningDataModule, seed_everything\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from torchmetrics import Accuracy, Precision, Recall\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from torchtext.models import RobertaClassificationHead, XLMR_BASE_ENCODER\n",
    "import torchtext.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.seed:Global seed set to 0\n"
     ]
    }
   ],
   "source": [
    "GLOBAL_SEED = 0\n",
    "seed_everything(GLOBAL_SEED, workers=True)\n",
    "CUDA_DEVICE_COUNT = torch.cuda.device_count()\n",
    "DATA_PATH = \"../../../data-davidson/data/labeled_data.csv\"\n",
    "NUM_WORKERS = 0\n",
    "MAX_LENGTH = 50\n",
    "DIMS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(LightningDataModule):\n",
    "    def __init__(self, path, fold_index = None, num_folds = None, batch_size = 32):\n",
    "        super().__init__()\n",
    "        self.val_sampler = None\n",
    "        self.train_sampler = None\n",
    "        self.val_fold = None\n",
    "        self.train_fold = None\n",
    "        self.splits = None\n",
    "        self.val_dataset = None\n",
    "        self.train_dataset = None\n",
    "\n",
    "        self.fold_index = fold_index\n",
    "        self.num_folds = num_folds\n",
    "        self.path = path\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.transform = XLMR_BASE_ENCODER.transform()\n",
    "\n",
    "\n",
    "    def read_csv_to_numpy(self, path):\n",
    "        data = pd.read_csv(path)\n",
    "        data = data.drop([\"Unnamed: 0\", \"count\", \"hate_speech\", \"offensive_language\", \"neither\"], axis=1)\n",
    "        data = data.reindex(columns=[\"tweet\", \"class\"])\n",
    "\n",
    "        df = data.drop(\n",
    "            data[data[\"class\"] == 1]\n",
    "            .sample(frac=0.92)\n",
    "            .index\n",
    "        )\n",
    "\n",
    "        df = df.drop(\n",
    "            df[df[\"class\"] == 2]\n",
    "            .sample(frac=0.65)\n",
    "            .index\n",
    "        )\n",
    "\n",
    "        return df.to_numpy()\n",
    "\n",
    "    def preprocess_data(self, batch):\n",
    "        x_arr, y_arr = [], []\n",
    "        for tweet, label in batch:\n",
    "\n",
    "            # space_pattern = '\\s+'\n",
    "            # giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "            #     '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "            # mention_regex = '@[\\w\\-]+'\n",
    "            # tweet = re.sub(space_pattern, ' ', tweet)\n",
    "            # tweet = re.sub(giant_url_regex, 'URLHERE', tweet)\n",
    "            # tweet = re.sub(mention_regex, 'MENTIONHERE', tweet)\n",
    "\n",
    "            transformed = self.transform(tweet)\n",
    "            x_arr.append(transformed)\n",
    "            y_arr.append(label)\n",
    "\n",
    "        x = F.to_tensor(x_arr, padding_value=1)\n",
    "        y = torch.tensor(y_arr)\n",
    "        \n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def setup(self, stage = None):\n",
    "        self.dataset = self.read_csv_to_numpy(self.path)\n",
    "        x_indices = list(range(len(self.dataset)))\n",
    "        \n",
    "        train_i, val_i = train_test_split(x_indices, test_size=0.2, stratify=self.dataset[:, 1], random_state=GLOBAL_SEED)\n",
    "\n",
    "        self.train_sampler = SubsetRandomSampler(train_i)\n",
    "        self.val_sampler = SubsetRandomSampler(val_i)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.dataset, batch_size=self.batch_size, sampler=self.train_sampler, num_workers=NUM_WORKERS, collate_fn=self.preprocess_data)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.dataset, batch_size=self.batch_size, sampler=self.val_sampler, num_workers=NUM_WORKERS, collate_fn=self.preprocess_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(LightningModule):\n",
    "    def __init__(self, learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.accuracy = Accuracy(num_classes=3)\n",
    "        self.precision_metric = Precision(num_classes=3)\n",
    "        self.recall = Recall(num_classes=3)\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        head = RobertaClassificationHead(num_classes=3, input_dim=768)\n",
    "        self.model = XLMR_BASE_ENCODER.get_model(head=head, freeze_encoder=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        \n",
    "        loss = self.loss(logits, y)\n",
    "\n",
    "        preds = self.softmax(logits)\n",
    "        acc = self.accuracy(preds, y)\n",
    "\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_acc', acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "\n",
    "        loss = self.loss(logits, y)\n",
    "\n",
    "        preds = self.softmax(logits)\n",
    "        acc = self.accuracy(preds, y)\n",
    "        pre = self.precision_metric(preds, y)\n",
    "        rec = self.recall(preds, y)\n",
    "\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_acc', acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        self.log('val_pre', pre, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_rec', rec, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        # self.log('val_spe', spe, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        # self.log('val_rocauc', rocauc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "\n",
    "    def predict_sentence(self, sentence):\n",
    "        transformed = XLMR_BASE_ENCODER.transform()(sentence)\n",
    "        transformed = F.to_tensor(transformed).unsqueeze(0)\n",
    "        logits = self(transformed).detach()\n",
    "        return {\n",
    "            \"probs\": self.softmax(logits),\n",
    "            \"class\": torch.argmax(logits)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "seed_everything(GLOBAL_SEED, workers=True)\n",
    "\n",
    "model = Net(learning_rate=1e-3)\n",
    "data = DataModule(path=DATA_PATH, batch_size=128)\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "trainer = Trainer(max_epochs=70, log_every_n_steps=20, gpus=CUDA_DEVICE_COUNT, callbacks=[early], deterministic=True)\n",
    "torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "trainer.fit(model=model, datamodule=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0509, 0.9388, 0.0103]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_sentence(\"you fucking piece of cunt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1819, 0.5572, 0.2609]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_sentence(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3514, 0.3726, 0.2761]]), tensor(1))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_sentence(\"you fucking piece of cunt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3513, 0.4330, 0.2158]]), tensor(1))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_sentence(\"it's a shame hitler didn't finish what he started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3301, 0.3230, 0.3469]]), tensor(2))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_sentence(\"nigga\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3160, 0.4213, 0.2627]]), tensor(1))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_sentence(\"i love my beautiful dogs\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5bc1c1bd0718088abbfd128e494961034fa09678758e3ccadbb62ed12465b326"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('bachelor-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
